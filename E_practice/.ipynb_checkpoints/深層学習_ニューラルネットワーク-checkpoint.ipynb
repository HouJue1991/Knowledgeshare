{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- forward:\n",
    "    - \n",
    "    - \n",
    "- gradient descent:\n",
    "    - gradient:\n",
    "        - $G_{W}:$\n",
    "        - $G_{b}:$\n",
    "      \n",
    "    - loss function\n",
    "        -  $Loss =- \\sum_{i=1}^{m} ylog(y_{hat}) + (1-y)log(1-y_{hat}) * (1/m) $\n",
    "    - update\n",
    "        - $W \\leftarrow  W- \\alpha G_{W}$\n",
    "        - $b \\leftarrow b- \\alpha G_{b}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(A_prev,W,b):\n",
    "     return np.dot(A_prev,W)+b\n",
    "    \n",
    "def der_linear(A_prev):\n",
    "#     np.dot(A_prev,W)+b\n",
    "#  derivative respect to w and b \n",
    "     return A_prev,1\n",
    "    \n",
    "def relu(Z):\n",
    "    return np.maximum(Z,0)\n",
    "    \n",
    "def der_relu(Z):\n",
    "    return np.where(Z>=0,1,0)\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "    \n",
    "def der_sigmoid(Z):\n",
    "    A = sigmoid(Z)\n",
    "    return A*(1-A)\n",
    "    \n",
    "def loss(A,Y):\n",
    "    m = Y.shape[0]\n",
    "    loss = -(1/m)*np.sum(Y*np.log(A) + (1-Y)*np.log(1-A))\n",
    "    return loss\n",
    "\n",
    "def loss_der(A,Y):\n",
    "    m = Y.shape[0]\n",
    "    loss_der = - (1/m) * np.sum((Y/A)  + (1-Y)/(1-A)) \n",
    "    return loss_der"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameter(n_x, n_h, n_y):\n",
    "    W1 = np.random.rand(n_x, n_h)\n",
    "    b1 =  np.random.rand(1，n_h)\n",
    "    W2 = np.random.rand(n_h, n_y)\n",
    "    b2 =  np.random.rand(1，n_y)\n",
    "    \n",
    "    parameters = {\n",
    "        \"W1\": W1,\n",
    "         \"b1\": b1,\n",
    "         \"W2\": W2,\n",
    "         \"b2\": b2\n",
    "                 }\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,params):\n",
    "    # define params\n",
    "    W1 = params['W1']\n",
    "    b1 = params['b1']\n",
    "    W2 = params['W2']\n",
    "    b2 = params['b2']\n",
    "    \n",
    "    ## layer 1 linear+relu\n",
    "    Z1 = linear(X,W1,b1)\n",
    "    A1 = relu(Z1)\n",
    "\n",
    "    ## layer 2:linear+sigmoid\n",
    "    Z2 = linear(A1,W2,b2)\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    cache= {\n",
    "        'X':X\n",
    "        'Z1':Z1\n",
    "        'A1':A1\n",
    "        'Z2':Z2\n",
    "    }\n",
    "    return A2,cache\n",
    "\n",
    "def predict(X,params):\n",
    "    y_test_hat,_ = forward(X,params)\n",
    "    y_test_hat = np.where(y_test_hat > 0.5, 1,0)\n",
    "    return y_test_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Z= WX+b → A = σ(Z) → L=loss(A,Y)\n",
    "- dZ/dW ← dA/dZ ←  dL/dA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- update parameters W and b use gradient descent\n",
    "- gradient descent：\n",
    "    - Wn = Wn - α dL/dw\n",
    "    - bn = bn - α dL/db\n",
    "- want：dL/dw , dL/db\n",
    "- use chain rule：dL/db = dL/dA * dA/dZ * dZ/dw\n",
    "    - dL/dA :\n",
    "        - (1/m) * sum((Y/A)  + (1-Y)/(1-A)) \n",
    "    - dA/dZ :\n",
    "        - relu : 1 if a >0 else 0 \n",
    "        - sigmoid:A(1-A)\n",
    "    - dZ/dw :\n",
    "        - X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([2,1])*np.array([2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([10,1,-1])\n",
    "der_relu(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(Y_hat , Y, cache):\n",
    "    \n",
    "    m = Y.shape[0]\n",
    "#     layer 2\n",
    "    dL_dA2 = der_loss(Y_hat,Y)\n",
    "    dA2_dZ2 = der_sigmoid(cache['Z2'])\n",
    "    dZ2_dW2,dZ2_db2 = der_linear(cache['A1'])\n",
    "    \n",
    "    dL_dW2 = dL_dA2*dA2_dZ2*dZ2_dW2\n",
    "    dL_db2 =  dL_dA2*dA2_dZ2*dZ2_db2\n",
    "    \n",
    "#     layer 1\n",
    "    dZ2_dA1 = W2\n",
    "    dA1_dZ1 = der_relu(cache['Z1'])\n",
    "    dZ1_dW1,dZ1_db1= der_linear(cache['X'])\n",
    "    \n",
    "    dL_dW1 = dL_dA2 *dA2_dZ2 * dZ2_dA1*dA1_dZ1*dZ1_dW1\n",
    "    dL_db1 =  dL_dA2 *dA2_dZ2 * dZ2_dA1*dA1_dZ1*dZ1_db1\n",
    "    \n",
    "    grads = {\n",
    "        'dW1':dL_dW1\n",
    "        ,'db1':dL_db1\n",
    "        ,'dW2':dL_dW2\n",
    "        ,'db2':dL_db2\n",
    "    }\n",
    "    return grads\n",
    "    \n",
    "\n",
    "def update(params,grads):\n",
    "    \n",
    "    params['W1'] -= LR * grads['dW1']  \n",
    "    params['b1'] -= LR * grads['db1']  \n",
    "    params['W2'] -= LR * grads['dW2']  \n",
    "    params['b2'] -= LR * grads['db2']  \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4)\n",
      "(105,)\n",
      "(45, 4)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "### initialize parameter\n",
    "ITER = 5\n",
    "LR = 0.01\n",
    "TEST_SIZE = 0.3\n",
    "grads = {\n",
    "    'dw':0\n",
    "    ,'db':0\n",
    "}\n",
    "\n",
    "### load data\n",
    "data_iris = load_iris()\n",
    "X,y = data_iris['data'],data_iris['target']\n",
    "# idx = y!=2\n",
    "# X,y =X[idx],y[idx]\n",
    "# idx_shuffle = np.random.permutation(range(X.shape[0]))\n",
    "# X,y =X[idx_shuffle],y[idx_shuffle]\n",
    "X,X_test ,y, y_test = train_test_split(X,y ,test_size = TEST_SIZE ,random_state = 0)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "initialize_parameter() missing 2 required positional arguments: 'n_h' and 'n_y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-fa21d134ff9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#initialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: initialize_parameter() missing 2 required positional arguments: 'n_h' and 'n_y'"
     ]
    }
   ],
   "source": [
    "#initialize\n",
    "w,b = initialize_parameter(X.shape[1])\n",
    "\n",
    "for i in range(100):\n",
    "#     forward\n",
    "    y_hat = forward(X,w,b)\n",
    "#     calculate grad,cost\n",
    "    grads = backward(y_hat , y)\n",
    "#     update\n",
    "    w = w - LR * grads['dw']  \n",
    "    b = b - LR * grads['db']\n",
    "    #calculate loss,matrics\n",
    "    if i%10 == 0 :\n",
    "        cost = loss(y_hat , y)\n",
    "        y_test_hat = predict(X_test,w,b)\n",
    "        accuracy =  accuracy_score(y_test_hat,y_test)\n",
    "        print('iter:{} , cost:{} ,accuracy:{} '.format(i,cost,accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3) (3, 4)\n"
     ]
    }
   ],
   "source": [
    "a1 = np.array([[1,2,3],[4,5,6]])\n",
    "a2 = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "print(a1.shape,a2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 38,  44,  50,  56],\n",
       "       [ 83,  98, 113, 128]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a1,a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
