{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "“RNN-task.ipynb”的副本",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CRW2Yo1ZhYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vICV7dkZhYw",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6KOmUWmdE-W",
        "colab_type": "code",
        "outputId": "28aa1655-888d-4e85-cfc2-a6f5261db7e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2020-01-08 14:00:15--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-01-08 14:00:15 (131 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "PWqM-R9hZhYy",
        "colab_type": "code",
        "outputId": "c4618631-0aec-47d4-f8bd-de2e84353994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiV0TYHdZhY3",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "tNwpTK9MZhY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "U62GsPUPZhY6",
        "colab_type": "code",
        "outputId": "db4f6503-ab86-4406-861a-8d8ee430f2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "gVpGC3bkZhY-",
        "colab_type": "code",
        "outputId": "b6db5f1b-abaf-43c3-db1d-df343f634619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ9/MLCMOfTOzjPx/p/4cUF1Gcl0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq8l-rMbZhZB",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4M7IZo2foe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "mhbB9eBxZhZC",
        "colab_type": "code",
        "outputId": "661895cd-c45d-4e4b-b590-426b1b851866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "set(''.join(names))\n",
        "\n",
        "tokens = list(tokens)\n",
        "tokens.extend('#')\n",
        "\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs1yP2uTZhZE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "IZ7uQjQhZhZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "token_to_id = {k: v for v, k in enumerate(tokens)} \n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIAKEQ-Dd4fV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token_to_id[pad_token]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "n-HFNAwkZhZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "Eua6wBEHZhZL",
        "colab_type": "code",
        "outputId": "815d17c6-0e58-4956-f745-d3df03ae8516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[25 40  3  6 34  6 44  2 55]\n",
            " [25 10  2 47  9 17 55 55 55]\n",
            " [25 23  9  0 24 24  0 44 55]\n",
            " [25 10  0 47 33  6 29 29 44]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCzPY-MQZhZO",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "04p9WOlzZhZP",
        "colab_type": "code",
        "outputId": "1dfc3136-cb4b-400b-e72d-c0abc1374d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "KZjKAVc5ZhZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='tanh')### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax')### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLyXSaHkZhZV",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "X87kHzVVZhZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h =  concatenate([x_t_emb, h_t])### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas =  get_probas(h_next)### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My8JETPjZhZa",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "DTKK2DOqZhZc",
        "colab_type": "code",
        "outputId": "b1f9c663-b2d0-42d5-c276-22552e118e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3535: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plzkEcmaZhZf",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "8qnQDkXZZhZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbRouqSYZhZk",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "cpf4T6pqZhZl",
        "colab_type": "code",
        "outputId": "117a6e4a-67f4-4a20-dc22-de91fd1cf49c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss =  tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))\n",
        "### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2749: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y2uOwmiZhZo",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "PWJ7W2q6ZhZq",
        "colab_type": "code",
        "outputId": "91c76582-ab6b-4aa2-af6f-f9ff2f664ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsocAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-iXUfkbZhZt",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "V_rXc02TZhZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "ukAJ4SuQZhZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "Ei9lpEgYZhZ3",
        "colab_type": "code",
        "outputId": "906e09d3-2086-4183-a891-38eaa7667092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " hane\n",
            " Benuy\n",
            " Hendiperra\n",
            " Gerkbe\n",
            " Sichiar\n",
            " Tardy\n",
            " Fanlan\n",
            " Tertare\n",
            " Bomar\n",
            " Carinealo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "mQ8Zo0JoZhZ5",
        "colab_type": "code",
        "outputId": "0785e6c7-cfdc-4646-fec8-6f4304843a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpa\n",
            " Trumpithe\n",
            " Trumpa\n",
            " Trumpa-ia\n",
            " Trumphe\n",
            " Trumpotiag\n",
            " Trumpaon\n",
            " Trumpor\n",
            " Trumpe\n",
            " Trumpan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za0sQZQQZhZ7",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "YSOfvq6YZhZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN ='5mgavDxrLm9uiTsf'\n",
        "# \"### YOUR TOKEN HERE ###\"\n",
        "COURSERA_EMAIL = 'houjue19910720@outlook.com'\n",
        "# \"### YOUR EMAIL HERE ###\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "E3rEkTBUZhZ-",
        "colab_type": "code",
        "outputId": "45c0f486-6a95-4302-deb4-a4a3caa78df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp8LnlDOZhaC",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "XdBdZqe6ZhaD",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "uCmx7Xn0ZhaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x2gHlxaZhaH",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "D3xlPwVrZhaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "NY9pgYXcZhaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}